2024-12-16 15:02:11,598 INFO    MainThread:24392 [wandb_setup.py:_flush():68] Current SDK version is 0.19.0
2024-12-16 15:02:11,598 INFO    MainThread:24392 [wandb_setup.py:_flush():68] Configure stats pid to 24392
2024-12-16 15:02:11,598 INFO    MainThread:24392 [wandb_setup.py:_flush():68] Loading settings from C:\Users\jarro\.config\wandb\settings
2024-12-16 15:02:11,598 INFO    MainThread:24392 [wandb_setup.py:_flush():68] Loading settings from C:\Users\jarro\Documents\GitHub\2023-24d-fai1-adsai-teamwork-t19\2024-25b-fai2-adsai-JarroTeunissen231667\datalab_tasks\task9\Reinforcement learning\wandb\settings
2024-12-16 15:02:11,598 INFO    MainThread:24392 [wandb_setup.py:_flush():68] Loading settings from environment variables
2024-12-16 15:02:11,601 INFO    MainThread:24392 [wandb_init.py:_log_setup():528] Logging user logs to C:\Users\jarro\Documents\GitHub\2023-24d-fai1-adsai-teamwork-t19\2024-25b-fai2-adsai-JarroTeunissen231667\datalab_tasks\task9\Reinforcement learning\wandb\run-20241216_150211-y7r403ed\logs\debug.log
2024-12-16 15:02:11,601 INFO    MainThread:24392 [wandb_init.py:_log_setup():529] Logging internal logs to C:\Users\jarro\Documents\GitHub\2023-24d-fai1-adsai-teamwork-t19\2024-25b-fai2-adsai-JarroTeunissen231667\datalab_tasks\task9\Reinforcement learning\wandb\run-20241216_150211-y7r403ed\logs\debug-internal.log
2024-12-16 15:02:11,601 INFO    MainThread:24392 [wandb_init.py:init():639] calling init triggers
2024-12-16 15:02:11,601 INFO    MainThread:24392 [wandb_init.py:init():645] wandb.init called with sweep_config: {}
config: {}
2024-12-16 15:02:11,601 INFO    MainThread:24392 [wandb_init.py:init():688] starting backend
2024-12-16 15:02:11,601 INFO    MainThread:24392 [wandb_init.py:init():692] sending inform_init request
2024-12-16 15:02:11,615 INFO    MainThread:24392 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=spawn, using: spawn
2024-12-16 15:02:11,617 INFO    MainThread:24392 [wandb_init.py:init():705] backend started and connected
2024-12-16 15:02:11,619 INFO    MainThread:24392 [wandb_init.py:init():798] updated telemetry
2024-12-16 15:02:11,843 INFO    MainThread:24392 [wandb_init.py:init():830] communicating run to backend with 90.0 second timeout
2024-12-16 15:02:13,108 INFO    MainThread:24392 [wandb_init.py:init():882] starting run threads in backend
2024-12-16 15:02:13,334 INFO    MainThread:24392 [wandb_run.py:_console_start():2443] atexit reg
2024-12-16 15:02:13,334 INFO    MainThread:24392 [wandb_run.py:_redirect():2293] redirect: wrap_raw
2024-12-16 15:02:13,334 INFO    MainThread:24392 [wandb_run.py:_redirect():2358] Wrapping output streams.
2024-12-16 15:02:13,334 INFO    MainThread:24392 [wandb_run.py:_redirect():2383] Redirects installed.
2024-12-16 15:02:13,335 INFO    MainThread:24392 [wandb_init.py:init():925] run started, returning control to user process
2024-12-16 15:02:13,872 INFO    MainThread:24392 [wandb_run.py:_tensorboard_callback():1532] tensorboard callback: runs/y7r403ed\runs/y7r403ed_0, True
2024-12-16 15:02:13,883 INFO    MainThread:24392 [wandb_run.py:_config_callback():1375] config_cb None None {'algo': 'PPO', 'policy_class': "<class 'stable_baselines3.common.policies.ActorCriticPolicy'>", 'device': 'cpu', 'verbose': 1, 'policy_kwargs': '{}', 'num_timesteps': 0, '_total_timesteps': 100000, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1734357733869010900, 'learning_rate': 0.0001, 'tensorboard_log': 'runs/y7r403ed', '_last_obs': '[[ 0.15793876 -0.98744893 -0.39734283]]', '_last_episode_starts': '[ True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x00000221BCF59730>', '_vec_normalize_env': 'None', 'observation_space': 'Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)', 'action_space': 'Box(-2.0, 2.0, (1,), float32)', 'n_envs': 1, 'n_steps': 2048, 'gamma': 0.99, 'gae_lambda': 0.95, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'rollout_buffer_class': "<class 'stable_baselines3.common.buffers.RolloutBuffer'>", 'rollout_buffer_kwargs': '{}', 'batch_size': 64, 'n_epochs': 10, 'clip_range': '<function get_schedule_fn.<locals>.<lambda> at 0x00000221C5E9FE50>', 'clip_range_vf': 'None', 'normalize_advantage': 'True', 'target_kl': 'None', 'lr_schedule': '<function get_schedule_fn.<locals>.<lambda> at 0x00000221BD055D30>', 'rollout_buffer': '<stable_baselines3.common.buffers.RolloutBuffer object at 0x0000022182AF8790>', 'policy': 'ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=3, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=3, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=64, out_features=1, bias=True)\n  (value_net): Linear(in_features=64, out_features=1, bias=True)\n)', '_logger': '<stable_baselines3.common.logger.Logger object at 0x00000221BD0423A0>'}
2024-12-16 15:02:14,306 WARNING MsgRouterThr:24392 [router.py:message_loop():75] message_loop has been closed
